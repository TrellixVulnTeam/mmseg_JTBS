{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73334a7-a1b2-4855-aa12-5dee30119cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/featurize/mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "%cd mmsegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23457fd7-fca9-4f44-8af0-93acf7bb39ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directories...\n",
      "Extracting training.zip...\n",
      "Generating training dataset...\n",
      "Extracting test.zip...\n",
      "Generating validation dataset...\n",
      "Removing the temporary files...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python tools/convert_datasets/drive.py ./dataset_zip/training.zip ./dataset_zip/test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bad931f-0f77-4d87-9f81-a9b9b336e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-25 14:53:00,451 - mmseg - INFO - Multi-processing start method is `None`\n",
      "2022-02-25 14:53:00,451 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>\n",
      "2022-02-25 14:53:00,515 - mmseg - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.10 (default, Jun  4 2021, 14:48:32) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3080\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.2.r11.2/compiler.29618528_0\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.10.0+cu113\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.11.1+cu113\n",
      "OpenCV: 4.5.4\n",
      "MMCV: 1.4.4\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 11.1\n",
      "MMSegmentation: 0.21.1+e5cd755\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-02-25 14:53:00,516 - mmseg - INFO - Distributed training: False\n",
      "2022-02-25 14:53:00,879 - mmseg - INFO - Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='UNet',\n",
      "        in_channels=3,\n",
      "        base_channels=64,\n",
      "        num_stages=5,\n",
      "        strides=(1, 1, 1, 1, 1),\n",
      "        enc_num_convs=(2, 2, 2, 2, 2),\n",
      "        dec_num_convs=(2, 2, 2, 2),\n",
      "        downsamples=(True, True, True, True),\n",
      "        enc_dilations=(1, 1, 1, 1, 1),\n",
      "        dec_dilations=(1, 1, 1, 1),\n",
      "        with_cp=False,\n",
      "        conv_cfg=None,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        act_cfg=dict(type='ReLU'),\n",
      "        upsample_cfg=dict(type='InterpConv'),\n",
      "        norm_eval=False),\n",
      "    decode_head=dict(\n",
      "        type='ASPPHead',\n",
      "        in_channels=64,\n",
      "        in_index=4,\n",
      "        channels=16,\n",
      "        dilations=(1, 12, 24, 36),\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=128,\n",
      "        in_index=3,\n",
      "        channels=64,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='slide', crop_size=(64, 64), stride=(42, 42)))\n",
      "dataset_type = 'DRIVEDataset'\n",
      "data_root = 'data/DRIVE'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "img_scale = (584, 565)\n",
      "crop_size = (64, 64)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(584, 565), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(64, 64), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(64, 64), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(584, 565),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=40000,\n",
      "        dataset=dict(\n",
      "            type='DRIVEDataset',\n",
      "            data_root='data/DRIVE',\n",
      "            img_dir='images/training',\n",
      "            ann_dir='annotations/training',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(584, 565),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='RandomCrop', crop_size=(64, 64), cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size=(64, 64), pad_val=0, seg_pad_val=255),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "            ])),\n",
      "    val=dict(\n",
      "        type='DRIVEDataset',\n",
      "        data_root='data/DRIVE',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(584, 565),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='DRIVEDataset',\n",
      "        data_root='data/DRIVE',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(584, 565),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=40000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=4000)\n",
      "evaluation = dict(interval=4000, metric='mDice', pre_eval=True)\n",
      "work_dir = './work_dirs/deeplabv3_unet_s5-d16_64x64_40k_drive'\n",
      "gpu_ids = [0]\n",
      "auto_resume = False\n",
      "\n",
      "2022-02-25 14:53:00,879 - mmseg - INFO - Set random seed to 1781212964, deterministic: False\n",
      "2022-02-25 14:53:01,284 - mmseg - INFO - initialize UNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "2022-02-25 14:53:01,472 - mmseg - INFO - initialize ASPPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-02-25 14:53:01,474 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "./tools/train.py:199: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n",
      "  'SyncBN is only supported with DDP. To be compatible with DP, '\n",
      "2022-02-25 14:53:01,480 - mmseg - INFO - EncoderDecoder(\n",
      "  (backbone): UNet(\n",
      "    (encoder): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): ModuleList(\n",
      "      (0): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "  (decode_head): ASPPHead(\n",
      "    input_transform=None, ignore_index=255, align_corners=False\n",
      "    (loss_decode): CrossEntropyLoss()\n",
      "    (conv_seg): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (image_pool): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (aspp_modules): ASPPModule(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "        (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "        (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "        (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (bottleneck): ConvModule(\n",
      "      (conv): Conv2d(80, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): _BatchNormXd(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activate): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "  (auxiliary_head): FCNHead(\n",
      "    input_transform=None, ignore_index=255, align_corners=False\n",
      "    (loss_decode): CrossEntropyLoss()\n",
      "    (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (convs): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      ")\n",
      "2022-02-25 14:53:01,484 - mmseg - INFO - Loaded 20 images\n",
      "2022-02-25 14:53:09,122 - mmseg - INFO - Loaded 20 images\n",
      "2022-02-25 14:53:09,122 - mmseg - INFO - Start running, host: featurize@featurize, work_dir: /home/featurize/mmsegmentation/work_dirs/deeplabv3_unet_s5-d16_64x64_40k_drive\n",
      "2022-02-25 14:53:09,123 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-02-25 14:53:09,123 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters\n",
      "2022-02-25 14:53:09,123 - mmseg - INFO - Checkpoints will be saved to /home/featurize/mmsegmentation/work_dirs/deeplabv3_unet_s5-d16_64x64_40k_drive by HardDiskBackend.\n",
      "2022-02-25 14:53:11,808 - mmseg - INFO - Iter [50/40000]\tlr: 9.989e-03, eta: 0:32:06, time: 0.048, data_time: 0.005, memory: 4533, decode.loss_ce: 0.5358, decode.acc_seg: 78.7767, aux.loss_ce: 0.2154, aux.acc_seg: 77.0101, loss: 0.7512\n",
      "2022-02-25 14:53:13,574 - mmseg - INFO - Iter [100/40000]\tlr: 9.978e-03, eta: 0:27:46, time: 0.035, data_time: 0.002, memory: 4533, decode.loss_ce: 0.5103, decode.acc_seg: 78.4492, aux.loss_ce: 0.2056, aux.acc_seg: 78.4492, loss: 0.7159\n",
      "2022-02-25 14:53:15,284 - mmseg - INFO - Iter [150/40000]\tlr: 9.967e-03, eta: 0:26:04, time: 0.034, data_time: 0.002, memory: 4533, decode.loss_ce: 0.4873, decode.acc_seg: 78.5359, aux.loss_ce: 0.1971, aux.acc_seg: 78.5035, loss: 0.6845\n",
      "2022-02-25 14:53:16,914 - mmseg - INFO - Iter [200/40000]\tlr: 9.956e-03, eta: 0:24:55, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.4694, decode.acc_seg: 79.2180, aux.loss_ce: 0.1910, aux.acc_seg: 78.7426, loss: 0.6604\n",
      "2022-02-25 14:53:18,560 - mmseg - INFO - Iter [250/40000]\tlr: 9.945e-03, eta: 0:24:16, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.4506, decode.acc_seg: 80.0909, aux.loss_ce: 0.1874, aux.acc_seg: 79.0656, loss: 0.6380\n",
      "2022-02-25 14:53:20,185 - mmseg - INFO - Iter [300/40000]\tlr: 9.933e-03, eta: 0:23:47, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.4010, decode.acc_seg: 83.2710, aux.loss_ce: 0.1645, aux.acc_seg: 82.7255, loss: 0.5655\n",
      "2022-02-25 14:53:21,767 - mmseg - INFO - Iter [350/40000]\tlr: 9.922e-03, eta: 0:23:21, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3918, decode.acc_seg: 83.4218, aux.loss_ce: 0.1615, aux.acc_seg: 82.9879, loss: 0.5533\n",
      "2022-02-25 14:53:23,451 - mmseg - INFO - Iter [400/40000]\tlr: 9.911e-03, eta: 0:23:11, time: 0.034, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3927, decode.acc_seg: 83.7559, aux.loss_ce: 0.1591, aux.acc_seg: 83.7778, loss: 0.5518\n",
      "2022-02-25 14:53:25,041 - mmseg - INFO - Iter [450/40000]\tlr: 9.900e-03, eta: 0:22:54, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3365, decode.acc_seg: 86.5516, aux.loss_ce: 0.1420, aux.acc_seg: 85.4752, loss: 0.4785\n",
      "2022-02-25 14:53:26,677 - mmseg - INFO - Iter [500/40000]\tlr: 9.889e-03, eta: 0:22:44, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3438, decode.acc_seg: 85.8951, aux.loss_ce: 0.1406, aux.acc_seg: 85.4934, loss: 0.4844\n",
      "2022-02-25 14:53:28,282 - mmseg - INFO - Iter [550/40000]\tlr: 9.878e-03, eta: 0:22:34, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3432, decode.acc_seg: 85.8995, aux.loss_ce: 0.1393, aux.acc_seg: 85.5106, loss: 0.4825\n",
      "2022-02-25 14:53:29,915 - mmseg - INFO - Iter [600/40000]\tlr: 9.866e-03, eta: 0:22:27, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.3411, decode.acc_seg: 86.0684, aux.loss_ce: 0.1357, aux.acc_seg: 86.0841, loss: 0.4769\n",
      "2022-02-25 14:53:31,527 - mmseg - INFO - Iter [650/40000]\tlr: 9.855e-03, eta: 0:22:19, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3157, decode.acc_seg: 87.3903, aux.loss_ce: 0.1284, aux.acc_seg: 87.1592, loss: 0.4441\n",
      "2022-02-25 14:53:33,089 - mmseg - INFO - Iter [700/40000]\tlr: 9.844e-03, eta: 0:22:09, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3248, decode.acc_seg: 86.6602, aux.loss_ce: 0.1331, aux.acc_seg: 86.4042, loss: 0.4578\n",
      "2022-02-25 14:53:34,637 - mmseg - INFO - Iter [750/40000]\tlr: 9.833e-03, eta: 0:22:00, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3196, decode.acc_seg: 86.7969, aux.loss_ce: 0.1271, aux.acc_seg: 86.8594, loss: 0.4468\n",
      "2022-02-25 14:53:36,264 - mmseg - INFO - Iter [800/40000]\tlr: 9.822e-03, eta: 0:21:56, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3154, decode.acc_seg: 87.4117, aux.loss_ce: 0.1265, aux.acc_seg: 87.4215, loss: 0.4419\n",
      "2022-02-25 14:53:37,798 - mmseg - INFO - Iter [850/40000]\tlr: 9.811e-03, eta: 0:21:47, time: 0.031, data_time: 0.002, memory: 4533, decode.loss_ce: 0.3106, decode.acc_seg: 87.7672, aux.loss_ce: 0.1257, aux.acc_seg: 87.4672, loss: 0.4363\n",
      "2022-02-25 14:53:39,333 - mmseg - INFO - Iter [900/40000]\tlr: 9.800e-03, eta: 0:21:40, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2970, decode.acc_seg: 88.0022, aux.loss_ce: 0.1190, aux.acc_seg: 88.0763, loss: 0.4161\n",
      "2022-02-25 14:53:40,886 - mmseg - INFO - Iter [950/40000]\tlr: 9.788e-03, eta: 0:21:34, time: 0.031, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2911, decode.acc_seg: 88.1823, aux.loss_ce: 0.1192, aux.acc_seg: 87.7233, loss: 0.4103\n",
      "2022-02-25 14:53:42,393 - mmseg - INFO - Exp name: deeplabv3_unet_s5-d16_64x64_40k_drive.py\n",
      "2022-02-25 14:53:42,394 - mmseg - INFO - Iter [1000/40000]\tlr: 9.777e-03, eta: 0:21:26, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.3033, decode.acc_seg: 87.5635, aux.loss_ce: 0.1223, aux.acc_seg: 87.6313, loss: 0.4256\n",
      "2022-02-25 14:53:43,974 - mmseg - INFO - Iter [1050/40000]\tlr: 9.766e-03, eta: 0:21:22, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2820, decode.acc_seg: 88.7633, aux.loss_ce: 0.1178, aux.acc_seg: 88.1963, loss: 0.3999\n",
      "2022-02-25 14:53:45,575 - mmseg - INFO - Iter [1100/40000]\tlr: 9.755e-03, eta: 0:21:19, time: 0.032, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2685, decode.acc_seg: 89.2369, aux.loss_ce: 0.1073, aux.acc_seg: 89.2068, loss: 0.3758\n",
      "2022-02-25 14:53:47,205 - mmseg - INFO - Iter [1150/40000]\tlr: 9.744e-03, eta: 0:21:16, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2930, decode.acc_seg: 88.4027, aux.loss_ce: 0.1172, aux.acc_seg: 88.2437, loss: 0.4103\n",
      "2022-02-25 14:53:48,745 - mmseg - INFO - Iter [1200/40000]\tlr: 9.733e-03, eta: 0:21:11, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2930, decode.acc_seg: 88.2023, aux.loss_ce: 0.1186, aux.acc_seg: 88.0991, loss: 0.4116\n",
      "2022-02-25 14:53:50,218 - mmseg - INFO - Iter [1250/40000]\tlr: 9.721e-03, eta: 0:21:05, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2875, decode.acc_seg: 88.2170, aux.loss_ce: 0.1160, aux.acc_seg: 88.2761, loss: 0.4035\n",
      "2022-02-25 14:53:51,862 - mmseg - INFO - Iter [1300/40000]\tlr: 9.710e-03, eta: 0:21:03, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2871, decode.acc_seg: 88.5977, aux.loss_ce: 0.1206, aux.acc_seg: 87.8702, loss: 0.4076\n",
      "2022-02-25 14:53:53,444 - mmseg - INFO - Iter [1350/40000]\tlr: 9.699e-03, eta: 0:21:00, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2768, decode.acc_seg: 88.8765, aux.loss_ce: 0.1125, aux.acc_seg: 88.6338, loss: 0.3893\n",
      "2022-02-25 14:53:55,043 - mmseg - INFO - Iter [1400/40000]\tlr: 9.688e-03, eta: 0:20:58, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2555, decode.acc_seg: 89.9686, aux.loss_ce: 0.1045, aux.acc_seg: 89.6432, loss: 0.3600\n",
      "2022-02-25 14:53:56,482 - mmseg - INFO - Iter [1450/40000]\tlr: 9.677e-03, eta: 0:20:51, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2751, decode.acc_seg: 89.0046, aux.loss_ce: 0.1116, aux.acc_seg: 88.9825, loss: 0.3867\n",
      "2022-02-25 14:53:58,022 - mmseg - INFO - Iter [1500/40000]\tlr: 9.665e-03, eta: 0:20:47, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2682, decode.acc_seg: 89.3110, aux.loss_ce: 0.1081, aux.acc_seg: 89.0400, loss: 0.3763\n",
      "2022-02-25 14:53:59,450 - mmseg - INFO - Iter [1550/40000]\tlr: 9.654e-03, eta: 0:20:41, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2771, decode.acc_seg: 88.8754, aux.loss_ce: 0.1123, aux.acc_seg: 88.7191, loss: 0.3894\n",
      "2022-02-25 14:54:00,946 - mmseg - INFO - Iter [1600/40000]\tlr: 9.643e-03, eta: 0:20:36, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2728, decode.acc_seg: 89.2915, aux.loss_ce: 0.1102, aux.acc_seg: 88.9354, loss: 0.3830\n",
      "2022-02-25 14:54:02,404 - mmseg - INFO - Iter [1650/40000]\tlr: 9.632e-03, eta: 0:20:31, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2581, decode.acc_seg: 89.9369, aux.loss_ce: 0.1057, aux.acc_seg: 89.5468, loss: 0.3638\n",
      "2022-02-25 14:54:03,931 - mmseg - INFO - Iter [1700/40000]\tlr: 9.621e-03, eta: 0:20:28, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2713, decode.acc_seg: 88.9899, aux.loss_ce: 0.1097, aux.acc_seg: 88.9764, loss: 0.3810\n",
      "2022-02-25 14:54:05,511 - mmseg - INFO - Iter [1750/40000]\tlr: 9.610e-03, eta: 0:20:26, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2686, decode.acc_seg: 89.3553, aux.loss_ce: 0.1086, aux.acc_seg: 89.1781, loss: 0.3772\n",
      "2022-02-25 14:54:07,036 - mmseg - INFO - Iter [1800/40000]\tlr: 9.598e-03, eta: 0:20:22, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2679, decode.acc_seg: 89.4259, aux.loss_ce: 0.1069, aux.acc_seg: 89.3290, loss: 0.3748\n",
      "2022-02-25 14:54:08,600 - mmseg - INFO - Iter [1850/40000]\tlr: 9.587e-03, eta: 0:20:20, time: 0.031, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2729, decode.acc_seg: 89.0833, aux.loss_ce: 0.1109, aux.acc_seg: 88.6552, loss: 0.3838\n",
      "2022-02-25 14:54:10,075 - mmseg - INFO - Iter [1900/40000]\tlr: 9.576e-03, eta: 0:20:16, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2685, decode.acc_seg: 89.4187, aux.loss_ce: 0.1091, aux.acc_seg: 89.1459, loss: 0.3776\n",
      "2022-02-25 14:54:11,595 - mmseg - INFO - Iter [1950/40000]\tlr: 9.565e-03, eta: 0:20:13, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2521, decode.acc_seg: 89.8213, aux.loss_ce: 0.1031, aux.acc_seg: 89.7351, loss: 0.3552\n",
      "2022-02-25 14:54:13,161 - mmseg - INFO - Exp name: deeplabv3_unet_s5-d16_64x64_40k_drive.py\n",
      "2022-02-25 14:54:13,161 - mmseg - INFO - Iter [2000/40000]\tlr: 9.554e-03, eta: 0:20:11, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2631, decode.acc_seg: 89.8021, aux.loss_ce: 0.1059, aux.acc_seg: 89.6257, loss: 0.3690\n",
      "2022-02-25 14:54:14,601 - mmseg - INFO - Iter [2050/40000]\tlr: 9.542e-03, eta: 0:20:06, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2483, decode.acc_seg: 90.3737, aux.loss_ce: 0.0992, aux.acc_seg: 90.3770, loss: 0.3475\n",
      "2022-02-25 14:54:16,120 - mmseg - INFO - Iter [2100/40000]\tlr: 9.531e-03, eta: 0:20:03, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2487, decode.acc_seg: 90.3058, aux.loss_ce: 0.0999, aux.acc_seg: 90.0885, loss: 0.3487\n",
      "2022-02-25 14:54:17,653 - mmseg - INFO - Iter [2150/40000]\tlr: 9.520e-03, eta: 0:20:01, time: 0.031, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2506, decode.acc_seg: 89.9327, aux.loss_ce: 0.1004, aux.acc_seg: 90.0557, loss: 0.3509\n",
      "2022-02-25 14:54:19,103 - mmseg - INFO - Iter [2200/40000]\tlr: 9.509e-03, eta: 0:19:57, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2566, decode.acc_seg: 89.8911, aux.loss_ce: 0.1030, aux.acc_seg: 89.8580, loss: 0.3597\n",
      "2022-02-25 14:54:20,698 - mmseg - INFO - Iter [2250/40000]\tlr: 9.498e-03, eta: 0:19:56, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2575, decode.acc_seg: 89.6772, aux.loss_ce: 0.1029, aux.acc_seg: 89.7491, loss: 0.3604\n",
      "2022-02-25 14:54:22,166 - mmseg - INFO - Iter [2300/40000]\tlr: 9.486e-03, eta: 0:19:52, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2466, decode.acc_seg: 90.3680, aux.loss_ce: 0.0994, aux.acc_seg: 90.3369, loss: 0.3460\n",
      "2022-02-25 14:54:23,692 - mmseg - INFO - Iter [2350/40000]\tlr: 9.475e-03, eta: 0:19:50, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2481, decode.acc_seg: 90.3492, aux.loss_ce: 0.1004, aux.acc_seg: 90.0692, loss: 0.3485\n",
      "2022-02-25 14:54:25,227 - mmseg - INFO - Iter [2400/40000]\tlr: 9.464e-03, eta: 0:19:47, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2535, decode.acc_seg: 90.2174, aux.loss_ce: 0.1018, aux.acc_seg: 90.1664, loss: 0.3553\n",
      "2022-02-25 14:54:26,672 - mmseg - INFO - Iter [2450/40000]\tlr: 9.453e-03, eta: 0:19:44, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2355, decode.acc_seg: 91.0668, aux.loss_ce: 0.0962, aux.acc_seg: 90.7108, loss: 0.3318\n",
      "2022-02-25 14:54:28,193 - mmseg - INFO - Iter [2500/40000]\tlr: 9.442e-03, eta: 0:19:41, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2763, decode.acc_seg: 88.9642, aux.loss_ce: 0.1107, aux.acc_seg: 89.0122, loss: 0.3870\n",
      "2022-02-25 14:54:29,701 - mmseg - INFO - Iter [2550/40000]\tlr: 9.430e-03, eta: 0:19:39, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2593, decode.acc_seg: 89.8219, aux.loss_ce: 0.1032, aux.acc_seg: 89.7036, loss: 0.3626\n",
      "2022-02-25 14:54:31,204 - mmseg - INFO - Iter [2600/40000]\tlr: 9.419e-03, eta: 0:19:36, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2469, decode.acc_seg: 90.2981, aux.loss_ce: 0.0993, aux.acc_seg: 90.3035, loss: 0.3463\n",
      "2022-02-25 14:54:32,665 - mmseg - INFO - Iter [2650/40000]\tlr: 9.408e-03, eta: 0:19:33, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2488, decode.acc_seg: 90.2225, aux.loss_ce: 0.1000, aux.acc_seg: 90.0138, loss: 0.3488\n",
      "2022-02-25 14:54:34,084 - mmseg - INFO - Iter [2700/40000]\tlr: 9.397e-03, eta: 0:19:29, time: 0.028, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2459, decode.acc_seg: 90.3638, aux.loss_ce: 0.0983, aux.acc_seg: 90.4486, loss: 0.3442\n",
      "2022-02-25 14:54:35,546 - mmseg - INFO - Iter [2750/40000]\tlr: 9.386e-03, eta: 0:19:26, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2446, decode.acc_seg: 90.5906, aux.loss_ce: 0.0988, aux.acc_seg: 90.2493, loss: 0.3434\n",
      "2022-02-25 14:54:36,901 - mmseg - INFO - Iter [2800/40000]\tlr: 9.374e-03, eta: 0:19:22, time: 0.027, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2646, decode.acc_seg: 89.6427, aux.loss_ce: 0.1069, aux.acc_seg: 89.4089, loss: 0.3715\n",
      "2022-02-25 14:54:38,324 - mmseg - INFO - Iter [2850/40000]\tlr: 9.363e-03, eta: 0:19:18, time: 0.028, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2580, decode.acc_seg: 89.7570, aux.loss_ce: 0.1032, aux.acc_seg: 89.8390, loss: 0.3612\n",
      "2022-02-25 14:54:39,799 - mmseg - INFO - Iter [2900/40000]\tlr: 9.352e-03, eta: 0:19:16, time: 0.029, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2391, decode.acc_seg: 90.4922, aux.loss_ce: 0.0961, aux.acc_seg: 90.4824, loss: 0.3351\n",
      "2022-02-25 14:54:41,355 - mmseg - INFO - Iter [2950/40000]\tlr: 9.341e-03, eta: 0:19:14, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2356, decode.acc_seg: 90.7754, aux.loss_ce: 0.0934, aux.acc_seg: 90.8400, loss: 0.3290\n",
      "2022-02-25 14:54:43,004 - mmseg - INFO - Exp name: deeplabv3_unet_s5-d16_64x64_40k_drive.py\n",
      "2022-02-25 14:54:43,004 - mmseg - INFO - Iter [3000/40000]\tlr: 9.329e-03, eta: 0:19:14, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2356, decode.acc_seg: 90.6512, aux.loss_ce: 0.0940, aux.acc_seg: 90.8082, loss: 0.3296\n",
      "2022-02-25 14:54:44,759 - mmseg - INFO - Iter [3050/40000]\tlr: 9.318e-03, eta: 0:19:15, time: 0.035, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2190, decode.acc_seg: 91.4443, aux.loss_ce: 0.0881, aux.acc_seg: 91.3375, loss: 0.3072\n",
      "2022-02-25 14:54:46,289 - mmseg - INFO - Iter [3100/40000]\tlr: 9.307e-03, eta: 0:19:13, time: 0.031, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2382, decode.acc_seg: 90.7781, aux.loss_ce: 0.0962, aux.acc_seg: 90.5522, loss: 0.3345\n",
      "2022-02-25 14:54:47,849 - mmseg - INFO - Iter [3150/40000]\tlr: 9.296e-03, eta: 0:19:11, time: 0.031, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2419, decode.acc_seg: 90.6638, aux.loss_ce: 0.0955, aux.acc_seg: 90.7964, loss: 0.3374\n",
      "2022-02-25 14:54:49,365 - mmseg - INFO - Iter [3200/40000]\tlr: 9.284e-03, eta: 0:19:09, time: 0.030, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2536, decode.acc_seg: 89.8693, aux.loss_ce: 0.1008, aux.acc_seg: 90.1454, loss: 0.3545\n",
      "2022-02-25 14:54:50,886 - mmseg - INFO - Iter [3250/40000]\tlr: 9.273e-03, eta: 0:19:07, time: 0.030, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2424, decode.acc_seg: 90.3569, aux.loss_ce: 0.0962, aux.acc_seg: 90.3938, loss: 0.3386\n",
      "2022-02-25 14:54:52,520 - mmseg - INFO - Iter [3300/40000]\tlr: 9.262e-03, eta: 0:19:06, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2340, decode.acc_seg: 91.1763, aux.loss_ce: 0.0930, aux.acc_seg: 91.0157, loss: 0.3270\n",
      "2022-02-25 14:54:54,123 - mmseg - INFO - Iter [3350/40000]\tlr: 9.251e-03, eta: 0:19:05, time: 0.032, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2429, decode.acc_seg: 90.3441, aux.loss_ce: 0.0957, aux.acc_seg: 90.6560, loss: 0.3386\n",
      "2022-02-25 14:54:55,855 - mmseg - INFO - Iter [3400/40000]\tlr: 9.240e-03, eta: 0:19:05, time: 0.035, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2371, decode.acc_seg: 90.8881, aux.loss_ce: 0.0940, aux.acc_seg: 90.9546, loss: 0.3311\n",
      "2022-02-25 14:54:57,600 - mmseg - INFO - Iter [3450/40000]\tlr: 9.228e-03, eta: 0:19:06, time: 0.035, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2419, decode.acc_seg: 90.5498, aux.loss_ce: 0.0978, aux.acc_seg: 90.4009, loss: 0.3397\n",
      "2022-02-25 14:54:59,204 - mmseg - INFO - Iter [3500/40000]\tlr: 9.217e-03, eta: 0:19:04, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2220, decode.acc_seg: 91.3057, aux.loss_ce: 0.0875, aux.acc_seg: 91.4031, loss: 0.3095\n",
      "2022-02-25 14:55:00,801 - mmseg - INFO - Iter [3550/40000]\tlr: 9.206e-03, eta: 0:19:03, time: 0.032, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2353, decode.acc_seg: 91.0255, aux.loss_ce: 0.0955, aux.acc_seg: 90.7747, loss: 0.3308\n",
      "2022-02-25 14:55:02,322 - mmseg - INFO - Iter [3600/40000]\tlr: 9.195e-03, eta: 0:19:01, time: 0.030, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2400, decode.acc_seg: 90.6190, aux.loss_ce: 0.0965, aux.acc_seg: 90.5336, loss: 0.3364\n",
      "2022-02-25 14:55:03,979 - mmseg - INFO - Iter [3650/40000]\tlr: 9.183e-03, eta: 0:19:00, time: 0.033, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2401, decode.acc_seg: 90.6155, aux.loss_ce: 0.0978, aux.acc_seg: 90.4105, loss: 0.3379\n",
      "2022-02-25 14:55:05,617 - mmseg - INFO - Iter [3700/40000]\tlr: 9.172e-03, eta: 0:18:59, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2286, decode.acc_seg: 91.1212, aux.loss_ce: 0.0916, aux.acc_seg: 90.8793, loss: 0.3201\n",
      "2022-02-25 14:55:07,318 - mmseg - INFO - Iter [3750/40000]\tlr: 9.161e-03, eta: 0:18:59, time: 0.034, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2406, decode.acc_seg: 90.7627, aux.loss_ce: 0.0959, aux.acc_seg: 90.6200, loss: 0.3365\n",
      "2022-02-25 14:55:08,988 - mmseg - INFO - Iter [3800/40000]\tlr: 9.150e-03, eta: 0:18:58, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2236, decode.acc_seg: 91.4680, aux.loss_ce: 0.0904, aux.acc_seg: 91.1729, loss: 0.3140\n",
      "2022-02-25 14:55:10,705 - mmseg - INFO - Iter [3850/40000]\tlr: 9.138e-03, eta: 0:18:58, time: 0.034, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2332, decode.acc_seg: 90.7667, aux.loss_ce: 0.0923, aux.acc_seg: 90.8590, loss: 0.3255\n",
      "2022-02-25 14:55:12,377 - mmseg - INFO - Iter [3900/40000]\tlr: 9.127e-03, eta: 0:18:58, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2446, decode.acc_seg: 90.0229, aux.loss_ce: 0.0972, aux.acc_seg: 90.2628, loss: 0.3418\n",
      "2022-02-25 14:55:14,008 - mmseg - INFO - Iter [3950/40000]\tlr: 9.116e-03, eta: 0:18:56, time: 0.033, data_time: 0.002, memory: 4533, decode.loss_ce: 0.2321, decode.acc_seg: 91.1050, aux.loss_ce: 0.0918, aux.acc_seg: 90.9493, loss: 0.3239\n",
      "2022-02-25 14:55:15,576 - mmseg - INFO - Saving checkpoint at 4000 iterations\n",
      "2022-02-25 14:55:16,321 - mmseg - INFO - Exp name: deeplabv3_unet_s5-d16_64x64_40k_drive.py\n",
      "2022-02-25 14:55:16,322 - mmseg - INFO - Iter [4000/40000]\tlr: 9.105e-03, eta: 0:19:02, time: 0.046, data_time: 0.001, memory: 4533, decode.loss_ce: 0.2292, decode.acc_seg: 91.0321, aux.loss_ce: 0.0923, aux.acc_seg: 90.8917, loss: 0.3215\n",
      "[                                                  ] 0/20, elapsed: 0s, ETA:Traceback (most recent call last):\n",
      "  File \"./tools/train.py\", line 234, in <module>\n",
      "    main()\n",
      "  File \"./tools/train.py\", line 230, in main\n",
      "    meta=meta)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/apis/train.py\", line 174, in train_segmentor\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 134, in run\n",
      "    iter_runner(iter_loaders[i], **kwargs)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/runner/iter_based_runner.py\", line 67, in train\n",
      "    self.call_hook('after_train_iter')\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 309, in call_hook\n",
      "    getattr(hook, fn_name)(self)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/runner/hooks/evaluation.py\", line 262, in after_train_iter\n",
      "    self._do_evaluate(runner)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/core/evaluation/eval_hooks.py\", line 50, in _do_evaluate\n",
      "    runner.model, self.dataloader, show=False, pre_eval=self.pre_eval)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/apis/test.py\", line 128, in single_gpu_test\n",
      "    result = dataset.pre_eval(result, indices=batch_indices)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/datasets/custom.py\", line 287, in pre_eval\n",
      "    seg_map = self.get_gt_seg_map_by_idx(index)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/datasets/custom.py\", line 247, in get_gt_seg_map_by_idx\n",
      "    self.gt_seg_map_loader(results)\n",
      "  File \"/home/featurize/mmsegmentation/mmseg/datasets/pipelines/loading.py\", line 132, in __call__\n",
      "    img_bytes = self.file_client.get(filename)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/fileio/file_client.py\", line 993, in get\n",
      "    return self.client.get(filepath)\n",
      "  File \"/environment/miniconda3/lib/python3.7/site-packages/mmcv/fileio/file_client.py\", line 518, in get\n",
      "    with open(filepath, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/DRIVE/annotations/validation/01_manual1.png'\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/train.py ./configs/unet/deeplabv3_unet_s5-d16_64x64_40k_drive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5e1b3-8128-4615-a3d2-ec84732f9379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
